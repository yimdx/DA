{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from tqdm.auto import *\n",
    "\n",
    "from diffgd.data import GraphDrawingData\n",
    "from diffgd.datasets import  RomeDataset\n",
    "from diffgd.metrics import Stress\n",
    "\n",
    "batch_size = 8\n",
    "lr = 0.001\n",
    "decay = 0.998\n",
    "train_size = 200\n",
    "num_steps = 1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "for backend, device_name in {\n",
    "    torch.backends.mps: \"mps\",\n",
    "    torch.cuda: \"cuda\",\n",
    "}.items():\n",
    "    if backend.is_available():\n",
    "        device = device_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuefengli/24fall/DeepAesthetic/.conda/lib/python3.10/site-packages/torch_geometric/data/dataset.py:213: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "/Users/xuefengli/24fall/DeepAesthetic/.conda/lib/python3.10/site-packages/torch_geometric/data/dataset.py:221: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "/Users/xuefengli/24fall/DeepAesthetic/DA/DiffusionGD/diffgd/datasets/rome_dataset.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.data_path)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfe757f460642fc8893f8621a360422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transform graphs:   0%|          | 0/11531 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11531\n"
     ]
    }
   ],
   "source": [
    "dataset = RomeDataset(\n",
    "    index=pd.read_csv(\"assets/rome_index.txt\", header=None)[0],\n",
    ")\n",
    "layouts = np.load(\"assets/layouts/pmds.npy\", allow_pickle=True)\n",
    "\n",
    "datalist = list(dataset)\n",
    "for i, data in enumerate(datalist):\n",
    "    data.pos = torch.tensor(layouts[i]).float()\n",
    "    data.feats = torch.randn((data.pos.shape[0], 16)).to(device)\n",
    "print(len(datalist))\n",
    "\n",
    "train_loader = pyg.loader.DataLoader(datalist[:train_size], batch_size=batch_size, shuffle=True)\n",
    "val_loader = pyg.loader.DataLoader(datalist[11000:], batch_size=batch_size, shuffle=False)\n",
    "test_loader = pyg.loader.DataLoader(datalist[10000:11000], batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_init_pos(batch):\n",
    "    # feats = torch.rand_like(batch.pos)\n",
    "    # feats = torch.ones((batch.pos.shape[0], 16)).to(device)\n",
    "    feats = torch.randn((batch.pos.shape[0], 16)).to(device)\n",
    "    feats, pos = generate_init(\n",
    "        feats=batch.feats,\n",
    "        pos=batch.pos,\n",
    "        apsp=batch.apsp_attr,\n",
    "        edge_index=batch.perm_index,\n",
    "        batch_index=batch.batch,\n",
    "    )\n",
    "    return feats, pos\n",
    "\n",
    "def get_edge_features(all_pair_shortest_path):\n",
    "    return torch.cat([\n",
    "        all_pair_shortest_path[:, None],\n",
    "        1 / all_pair_shortest_path[:, None].square()\n",
    "    ], dim=-1)\n",
    "\n",
    "def generate_init(feats, pos, apsp, edge_index, batch_index):\n",
    "    return feats, rescale_by_stress(pos, apsp, edge_index, batch_index)\n",
    "    \n",
    "def get_edge_features(all_pair_shortest_path):\n",
    "    return torch.cat([\n",
    "        all_pair_shortest_path[:, None],\n",
    "        1 / all_pair_shortest_path[:, None].square()\n",
    "    ], dim=-1)\n",
    "\n",
    "def rescale_by_stress(pos, apsp, edge_index, batch_index):\n",
    "    src_pos, dst_pos = pos[edge_index[0]], pos[edge_index[1]]\n",
    "    dist = (dst_pos - src_pos).norm(dim=1)\n",
    "    u_over_d = dist / apsp\n",
    "    scatterd_u_over_d_2 = pyg.utils.scatter(u_over_d ** 2, batch_index[edge_index[0]])\n",
    "    scatterd_u_over_d = pyg.utils.scatter(u_over_d, batch_index[edge_index[0]])\n",
    "    scale = scatterd_u_over_d_2 / scatterd_u_over_d\n",
    "    return pos / scale[batch_index][:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Stress()\n",
    "def sample(model, batch, device, num_timesteps=1000):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.randn_like(batch.pos).to(device)\n",
    "        \n",
    "        for i in reversed(range(num_timesteps)):\n",
    "            t = torch.full((batch.batch_size,), i, device=device, dtype=torch.long)\n",
    "            x = model.p_sample(x, t)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def train_diffusion(model, train_loader, optim, scheduler, device, num_epochs=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        scores = []\n",
    "        for batch_idx, batch in enumerate(tqdm(train_loader)):\n",
    "            batch = batch.to(device)\n",
    "            model.zero_grad()\n",
    "            \n",
    "            t = torch.randint(0, model.timesteps, (1,)).item()\n",
    "            \n",
    "            node_feats, init_pos = generate_init_pos(batch)\n",
    "            \n",
    "            loss = model.p_losses(\n",
    "                x_start=init_pos,\n",
    "                node_feat=node_feats,\n",
    "                edge_index=batch.perm_index,\n",
    "                edge_attr=get_edge_features(batch.apsp_attr),\n",
    "                batch_index=batch.batch,\n",
    "                t=t,\n",
    "            )\n",
    "            \n",
    "            pred = model.sample(\n",
    "                node_feat=node_feats,\n",
    "                edge_index=batch.perm_index,\n",
    "                edge_attr=get_edge_features(batch.apsp_attr),\n",
    "                batch_index=batch.batch,\n",
    "            )\n",
    "            pred = rescale_by_stress(pred, batch.apsp_attr, batch.perm_index, batch.batch)\n",
    "            # score = c(pred, batch.apsp_attr, batch.perm_index, batch.batch, batch.edge_pair_index)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            losses.append(loss.item())\n",
    "            # scores.append(score)\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(f'[Epoch {epoch}] Train Loss: {np.mean(losses)}, score = {np.mean(scores)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGNNBasicLayer.Config(dense=False, bn='pyg_batch_norm', act='leaky_relu', dp=0.0, residual=False, aggr='mean', root_weight=True, norm=True)\n",
      "EGNNBasicLayer.Config(dense=False, bn='pyg_batch_norm', act='leaky_relu', dp=0.0, residual=False, aggr='mean', root_weight=True, norm=True)\n",
      "EGNNBasicLayer.Config(dense=False, bn='pyg_batch_norm', act='leaky_relu', dp=0.0, residual=False, aggr='mean', root_weight=True, norm=True)\n",
      "EGNNBasicLayer.Config(dense=False, bn='pyg_batch_norm', act='leaky_relu', dp=0.0, residual=False, aggr='mean', root_weight=True, norm=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b387338b07dc4b89b3061de09950ebc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train Loss: nan, score = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuefengli/24fall/DeepAesthetic/.conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/xuefengli/24fall/DeepAesthetic/.conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762a758fe1f14ddea4f824ac0236e94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optim, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(model.sqrt_one_minus_alphas_cumprod.shape)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain_diffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(test_loader)):\n\u001b[1;32m     11\u001b[0m     node_feats, init_pos \u001b[38;5;241m=\u001b[39m generate_init_pos(batch)\n",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m, in \u001b[0;36mtrain_diffusion\u001b[0;34m(model, train_loader, optim, scheduler, device, num_epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, model\u001b[38;5;241m.\u001b[39mtimesteps, (\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     24\u001b[0m node_feats, init_pos \u001b[38;5;241m=\u001b[39m generate_init_pos(batch)\n\u001b[0;32m---> 26\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_losses\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_feat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperm_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_edge_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapsp_attr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m     36\u001b[0m     node_feat\u001b[38;5;241m=\u001b[39mnode_feats,\n\u001b[1;32m     37\u001b[0m     edge_index\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mperm_index,\n\u001b[1;32m     38\u001b[0m     edge_attr\u001b[38;5;241m=\u001b[39mget_edge_features(batch\u001b[38;5;241m.\u001b[39mapsp_attr),\n\u001b[1;32m     39\u001b[0m     batch_index\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mbatch,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m pred \u001b[38;5;241m=\u001b[39m rescale_by_stress(pred, batch\u001b[38;5;241m.\u001b[39mapsp_attr, batch\u001b[38;5;241m.\u001b[39mperm_index, batch\u001b[38;5;241m.\u001b[39mbatch)\n",
      "File \u001b[0;32m~/24fall/DeepAesthetic/DA/DiffusionGD/diffgd/model/diffusion/generator.py:81\u001b[0m, in \u001b[0;36mDiffusionModel.p_losses\u001b[0;34m(self, x_start, node_feat, edge_index, edge_attr, batch_index, t)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_losses\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_start, node_feat, edge_index, edge_attr, batch_index, t):\n\u001b[1;32m     80\u001b[0m     noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x_start)\n\u001b[0;32m---> 81\u001b[0m     x_noisy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     _, pred_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m     83\u001b[0m         coords\u001b[38;5;241m=\u001b[39mx_noisy,\n\u001b[1;32m     84\u001b[0m         node_feat\u001b[38;5;241m=\u001b[39mnode_feat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m         t\u001b[38;5;241m=\u001b[39mt,\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(pred_noise, noise)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from diffgd.model import DiffusionModel\n",
    "\n",
    "model = DiffusionModel(in_dim=16, out_dim=32, num_layers=4, edge_feat_dim=2, timesteps=200, device=device).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=10, gamma=0.1)\n",
    "# print(model.sqrt_one_minus_alphas_cumprod.shape)\n",
    "# Train the model\n",
    "train_diffusion(model, train_loader, optim, scheduler, device, num_epochs=20)\n",
    "\n",
    "for batch_idx, batch in enumerate(tqdm(test_loader)):\n",
    "    node_feats, init_pos = generate_init_pos(batch)\n",
    "    sampled_coords = model.sample(\n",
    "        node_feat=node_feats,\n",
    "        edge_index=batch.perm_index,\n",
    "        edge_attr=get_edge_features(batch.apsp_attr),\n",
    "        batch_index=batch.batch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGNNBasicLayer.Config(dense=False, bn='batch_norm', act='leaky_relu', dp=0.0, residual=False, aggr='mean', root_weight=True, norm=True)\n",
      "EGNNBasicLayer.Config(dense=False, bn='batch_norm', act='leaky_relu', dp=0.0, residual=False, aggr='mean', root_weight=True, norm=True)\n",
      "EGNNBasicLayer.Config(dense=False, bn='batch_norm', act='leaky_relu', dp=0.0, residual=False, aggr='mean', root_weight=True, norm=True)\n",
      "EGNNBasicLayer.Config(dense=False, bn='batch_norm', act='leaky_relu', dp=0.0, residual=False, aggr='mean', root_weight=True, norm=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m\n\u001b[1;32m     14\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, model\u001b[38;5;241m.\u001b[39mtimesteps, (\u001b[38;5;241m16\u001b[39m,), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Calling the model's loss function with fixed parameters\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mp_losses(\n\u001b[1;32m     18\u001b[0m     x_start\u001b[38;5;241m=\u001b[39minit_pos,\n\u001b[1;32m     19\u001b[0m     node_feat\u001b[38;5;241m=\u001b[39mnode_feats,\n\u001b[1;32m     20\u001b[0m     edge_index\u001b[38;5;241m=\u001b[39mperm_index,\n\u001b[1;32m     21\u001b[0m     edge_attr\u001b[38;5;241m=\u001b[39medge_attr,  \u001b[38;5;66;03m# Corrected edge_attr\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     batch_index\u001b[38;5;241m=\u001b[39m\u001b[43mbatch\u001b[49m\u001b[38;5;241m.\u001b[39mbatch,  \u001b[38;5;66;03m# If this should be a tensor, use torch.tensor(0)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     t\u001b[38;5;241m=\u001b[39mt\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "model = DiffusionModel(in_dim=16, out_dim=16, num_layers=4, edge_feat_dim=2, timesteps=1000, device='cpu').to('cpu')\n",
    "\n",
    "init_pos = torch.rand((16, 2))\n",
    "node_feats = torch.rand((16, 16))\n",
    "perm_index = torch.ones((2, 240), dtype=torch.long)\n",
    "\n",
    "edge_attr = torch.ones((240, 2))  # Creates a proper (240, 2) tensor\n",
    "t = torch.randint(0, model.timesteps, (16,), device='cpu').long()\n",
    "\n",
    "loss = model.p_losses(\n",
    "    x_start=init_pos,\n",
    "    node_feat=node_feats,\n",
    "    edge_index=perm_index,\n",
    "    edge_attr=edge_attr,\n",
    "    batch_index=batch.batch,\n",
    "    t=t\n",
    ")\n",
    "\n",
    "print(loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
