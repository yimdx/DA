{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61bcb190-671c-4e75-9469-1bd4c801c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5d7c53-d37c-4c03-9713-cd8ffaa6d0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/li.xuefen/gd_test/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from tqdm.auto import *\n",
    "\n",
    "from smartgd.model import Generator, Discriminator\n",
    "from smartgd.data import GraphDrawingData\n",
    "from smartgd.datasets import  RomeDataset\n",
    "from smartgd.metrics import Stress, Crossings\n",
    "from smartgd.transformations import Compose, Center, NormalizeRotation, RescaleByStress\n",
    "from smartgd.criteria import RGANCriterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ecb6a05-deff-4ebc-a4be-7e3bd2ffada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "for backend, device_name in {\n",
    "    # torch.backends.mps: \"mps\",\n",
    "    torch.cuda: \"cuda\",\n",
    "}.items():\n",
    "    if backend.is_available():\n",
    "        device = device_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31fa6e3c690c3c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"stress\"\n",
    "batch_size = 32\n",
    "start_epoch = 0\n",
    "max_epoch = 100\n",
    "max_lr = 0.01\n",
    "min_lr = 0.0001\n",
    "wr_period = 200\n",
    "train_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5438faa-6332-46be-92c3-f80337e46009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dddd78540d04dc59d7ae70f52a5a889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transform graphs:   0%|          | 0/11531 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GraphDrawingData.set_optional_fields([\n",
    "    \"edge_pair_metaindex\",\n",
    "    # \"face\",\n",
    "    # \"rng\"\n",
    "])\n",
    "dataset = RomeDataset(\n",
    "    index=pd.read_csv(\"assets/rome_index.txt\", header=None)[0],\n",
    ")\n",
    "init_layouts = np.load(\"assets/layouts/aligned_positions.npy\", allow_pickle=True)\n",
    "target_layouts = np.load(\"assets/layouts/aligned_positions.npy\", allow_pickle=True)\n",
    "generator = Generator(\n",
    "    params=Generator.Params(\n",
    "        num_blocks=11,\n",
    "        block_depth=3,\n",
    "        block_width=8,\n",
    "        block_output_dim=8,\n",
    "        edge_net_depth=2,\n",
    "        edge_net_width=16,\n",
    "        edge_attr_dim=2,\n",
    "        node_attr_dim=2,\n",
    "    ),\n",
    ").to(device)\n",
    "discriminator = Discriminator(\n",
    "    params=Discriminator.Params(\n",
    "        num_layers=9,\n",
    "        hidden_width=16,\n",
    "        edge_net_shared_depth=8,\n",
    "        edge_net_embedded_depth=8,\n",
    "        edge_net_width=64,\n",
    "        edge_attr_dim=2\n",
    "    )\n",
    ").to(device)\n",
    "canonicalizer = Compose(\n",
    "    Center(),\n",
    "    NormalizeRotation(),\n",
    "    RescaleByStress(),\n",
    ")\n",
    "metrics = {\n",
    "    Stress(): 1,\n",
    "    # Crossings(): 1,\n",
    "    # dgd.EdgeVar(): 0,\n",
    "    # dgd.Occlusion(): 0,\n",
    "    # dgd.IncidentAngle(): 0,\n",
    "    # dgd.TSNEScore(): 0,\n",
    "}\n",
    "tie_break_metrics = {\n",
    "    Stress(): 1\n",
    "}\n",
    "criterion = RGANCriterion()\n",
    "gen_optim = torch.optim.AdamW(generator.parameters(), lr=max_lr)\n",
    "dis_optim = torch.optim.AdamW(discriminator.parameters(), lr=max_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20544c19d8ad0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if start_epoch:\n",
    "#     generator.load_state_dict(torch.load(f\"./human_label_model/generator_{start_epoch-1}.pt\"))\n",
    "#     discriminator.load_state_dict(torch.load(f\"./human_label_model/discriminator_{start_epoch-1}.pt\"))\n",
    "#     gen_optim.load_state_dict(torch.load(f\"./human_label_model/gen_optim_{start_epoch-1}.pt\"))\n",
    "#     dis_optim.load_state_dict(torch.load(f\"./human_label_model/dis_optim_{start_epoch-1}.pt\"))\n",
    "#     target_layouts = torch.load(f\"./human_label_model/layouts_{start_epoch-1}.pt\")\n",
    "gen_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(gen_optim, T_0=wr_period, eta_min=min_lr, last_epoch=start_epoch-1)\n",
    "dis_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(dis_optim, T_0=wr_period, eta_min=min_lr, last_epoch=start_epoch-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60bc240f4580a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "outlier_graph_ids = set()\n",
    "with open('./assets/layouts/no_label_outlier.csv', mode='r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    outlier_graph_ids = {row['graph_id'] for row in reader}\n",
    "# print(outlier_graph_ids)\n",
    "def create_dataloaders():\n",
    "    datalist = list(dataset)\n",
    "    for i, data in enumerate(datalist):\n",
    "        data.pos = torch.tensor(init_layouts[i]).float()\n",
    "        data.target_pos = torch.tensor(target_layouts[i]).float()\n",
    "        data.fake_pos = torch.zeros_like(data.target_pos)\n",
    "        data.index = i\n",
    "\n",
    "    filtered_train = [\n",
    "        data for i, data in enumerate(datalist[:train_size])\n",
    "        if data.G.graph[\"name\"] not in outlier_graph_ids\n",
    "    ]\n",
    "    # print(len(filtered_train))\n",
    "    train_loader = pyg.loader.DataLoader(filtered_train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = pyg.loader.DataLoader(datalist[11000:], batch_size=batch_size, shuffle=False)\n",
    "    test_loader = pyg.loader.DataLoader(datalist[10000:11000], batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "933f88a3b2e9bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_init_pos(batch):\n",
    "    # pos = torch.rand_like(batch.pos)\n",
    "    pos = canonicalizer(\n",
    "        pos=batch.pos,\n",
    "        apsp=batch.apsp_attr,\n",
    "        edge_index=batch.perm_index,\n",
    "        batch_index=batch.batch,\n",
    "    )\n",
    "    return pos\n",
    "\n",
    "def get_edge_features(all_pair_shortest_path):\n",
    "    return torch.cat([\n",
    "        all_pair_shortest_path[:, None],\n",
    "        1 / all_pair_shortest_path[:, None].square()\n",
    "    ], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4054476395c36e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pos, batch):\n",
    "    score = 0\n",
    "    for c, w in metrics.items():\n",
    "        score += w * c(pos, batch.perm_index, batch.apsp_attr, batch.batch, batch.edge_pair_index)\n",
    "    return score\n",
    "\n",
    "def evaluate_tie(pos, batch):\n",
    "    score = 0\n",
    "    for c, w in tie_break_metrics.items():\n",
    "        score += w * c(pos, batch.perm_index, batch.apsp_attr, batch.batch, batch.edge_pair_index)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f266d1f162a0d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(batch, train=False):\n",
    "    edge_attr = get_edge_features(batch.apsp_attr)\n",
    "    pred = generator(\n",
    "        init_pos=generate_init_pos(batch),\n",
    "        edge_index=batch.perm_index,\n",
    "        edge_attr=edge_attr,\n",
    "        batch_index=batch.batch,\n",
    "    )\n",
    "    fake_pos = canonicalizer(pred, batch.apsp_attr, batch.perm_index, batch.batch)\n",
    "    fake_score = evaluate(fake_pos, batch)\n",
    "    output = {\n",
    "        'fake_pos': fake_pos,\n",
    "        'fake_score': fake_score,\n",
    "    }\n",
    "    if train:\n",
    "        fake_tie_break_score = evaluate_tie(fake_pos, batch)\n",
    "        fake_logits = discriminator(\n",
    "            # coords=fake_pos,\n",
    "            pos=fake_pos,\n",
    "            edge_index=batch.perm_index,\n",
    "            edge_attr=edge_attr,\n",
    "            batch_index=batch.batch,\n",
    "        )\n",
    "        # print(batch.target_pos.shape)\n",
    "        real_pos = canonicalizer(batch.target_pos, batch.apsp_attr, batch.perm_index, batch.batch)\n",
    "        real_score = evaluate(real_pos, batch)\n",
    "        real_tie_break_score = evaluate_tie(real_pos, batch)\n",
    "        real_logits = discriminator(\n",
    "            # coords=real_pos,\n",
    "            pos=real_pos,\n",
    "            edge_index=batch.perm_index,\n",
    "            edge_attr=edge_attr,\n",
    "            batch_index=batch.batch,\n",
    "        )\n",
    "        fake_better = (fake_score < real_score) | ((fake_score == real_score) & (fake_tie_break_score < real_tie_break_score))\n",
    "        good_logits = torch.cat([\n",
    "            fake_logits[fake_better],\n",
    "            real_logits[~fake_better],\n",
    "        ])\n",
    "        bad_logits = torch.cat([\n",
    "            real_logits[fake_better],\n",
    "            fake_logits[~fake_better],\n",
    "        ])\n",
    "        output |= {\n",
    "            'fake_logits': fake_logits,\n",
    "            'real_pos': real_pos,\n",
    "            'real_score': real_score,\n",
    "            'real_logits': real_logits,\n",
    "            'good_logits': good_logits,\n",
    "            'bad_logits': bad_logits,\n",
    "            'fake_better': fake_better,\n",
    "        }\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d175bef99479dd09",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cf4fa59-3c2a-49b2-9f03-8537ae1e1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = create_dataloaders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "840e2975-0553-4e47-952d-a3ae1a57928a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14a637e73e34c63afcee498caf583e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/li.xuefen/gd_test/lib/python3.10/site-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Learning Rates:\tgen=0.00999938933078422\tdis=0.00999938933078422\n",
      "[Epoch 0] Train Loss:\tgen=nan\tdis=nan\n",
      "[Epoch 0] Train Score:\tnan/280.8322743466445\n",
      "[Epoch 0] Replacements:\t0\n",
      "[Epoch 0] Test Score:\tnan\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b30fa94fec74772b5dce8d3e57a53a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Learning Rates:\tgen=0.009997557473810372\tdis=0.009997557473810372\n",
      "[Epoch 1] Train Loss:\tgen=nan\tdis=nan\n",
      "[Epoch 1] Train Score:\tnan/280.8322652039351\n",
      "[Epoch 1] Replacements:\t0\n",
      "[Epoch 1] Test Score:\tnan\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e290ac5e6e14104844e919cf016278c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m output \u001b[38;5;241m=\u001b[39m forward(batch, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m gen_loss \u001b[38;5;241m=\u001b[39m criterion(encourage\u001b[38;5;241m=\u001b[39moutput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbad_logits\u001b[39m\u001b[38;5;124m'\u001b[39m], discourage\u001b[38;5;241m=\u001b[39moutput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgood_logits\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 25\u001b[0m \u001b[43mgen_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m gen_optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m gen_losses\u001b[38;5;241m.\u001b[39mappend(gen_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/scratch/li.xuefen/gd_test/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/li.xuefen/gd_test/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, max_epoch):\n",
    "    train_loader, val_loader, test_loader = create_dataloaders()\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    gen_losses = []\n",
    "    dis_losses = []\n",
    "    fake_scores = []\n",
    "    real_scores = []\n",
    "    replacements = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        generator.zero_grad()\n",
    "        discriminator.zero_grad()\n",
    "        output = forward(batch, train=True)\n",
    "        dis_loss = criterion(encourage=output['good_logits'], discourage=output['bad_logits'])\n",
    "        dis_loss.backward()\n",
    "        dis_optim.step()\n",
    "\n",
    "        generator.zero_grad()\n",
    "        discriminator.zero_grad()\n",
    "        output = forward(batch, train=True)\n",
    "        gen_loss = criterion(encourage=output['bad_logits'], discourage=output['good_logits'])\n",
    "        gen_loss.backward()\n",
    "        gen_optim.step()\n",
    "\n",
    "        gen_losses.append(gen_loss.item())\n",
    "        dis_losses.append(dis_loss.item())\n",
    "        fake_scores += output['fake_score'].tolist()\n",
    "        real_scores += output['real_score'].tolist()\n",
    "\n",
    "        batch.fake_pos = output['fake_pos']\n",
    "        for fake_better, data in zip(output['fake_better'], batch.to_data_list()):\n",
    "            if fake_better:\n",
    "                target_layouts[data['index']] = data['fake_pos'].detach().cpu().numpy()\n",
    "                replacements += 1\n",
    "\n",
    "    gen_scheduler.step()\n",
    "    dis_scheduler.step()\n",
    "    print(f'[Epoch {epoch}] Learning Rates:\\tgen={gen_scheduler.get_last_lr()[0]}\\tdis={dis_scheduler.get_last_lr()[0]}')\n",
    "    print(f'[Epoch {epoch}] Train Loss:\\tgen={np.mean(gen_losses)}\\tdis={np.mean(dis_losses)}')\n",
    "    print(f'[Epoch {epoch}] Train Score:\\t{np.mean(fake_scores)}/{np.mean(real_scores)}')\n",
    "    print(f'[Epoch {epoch}] Replacements:\\t{replacements}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generator.eval()\n",
    "        discriminator.eval()\n",
    "        scores = []\n",
    "        for batch in tqdm(test_loader, disable=True):\n",
    "            batch = batch.to(device)\n",
    "            output = forward(batch)\n",
    "            scores += output['fake_score'].tolist()\n",
    "\n",
    "        print(f'[Epoch {epoch}] Test Score:\\t{np.mean(scores)}')\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(generator.state_dict(), f\"./egnn/generator_{epoch}.pt\")\n",
    "        torch.save(discriminator.state_dict(), f\"./egnn/discriminator_{epoch}.pt\")\n",
    "        torch.save(gen_optim.state_dict(), f\"./egnn/gen_optim_{epoch}.pt\")\n",
    "        torch.save(dis_optim.state_dict(), f\"./egnn/dis_optim_{epoch}.pt\")\n",
    "        torch.save(target_layouts, f\"./egnn/layouts_{epoch}.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf86b48-6452-4b71-a819-9842c29ac013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "343084810e149ec6",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df250c999ffe626",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_loader, test_loader = create_dataloaders()\n",
    "for epoch in range(0, 500, 20):\n",
    "\n",
    "    generator.load_state_dict(torch.load(f\"human_label_model/generator_{epoch}.pt\"))\n",
    "    discriminator.load_state_dict(torch.load(f\"human_label_model/discriminator_{epoch}.pt\"))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generator.eval()\n",
    "        # discriminator.eval()\n",
    "        scores = []\n",
    "        for batch in tqdm(test_loader, disable=True):\n",
    "            batch = batch.to(device)\n",
    "            output = forward(batch)\n",
    "            scores += output['fake_score'].tolist()\n",
    "\n",
    "        print(f'[Epoch {epoch}] Test Score:\\t{np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daafc65c-8e9d-41d4-9310-61cc7c4ff9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a799f7-1eef-490d-85b4-abde38a9a586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6f920-cd4a-4ce5-b0e8-bc6009e02ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1a6eaadc214a40b8a2fa048f934db6d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_40c664d572b84ef18b87ead26e1394fd",
       "style": "IPY_MODEL_80769a69b258448ba022beb13ba6364a",
       "value": " 2/79 [03:39&lt;2:08:39, 100.26s/it]"
      }
     },
     "1d73892e8c254708ad3918446d1b971d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_27d2c0b03e77463ca2d1ef57e2dbb80c",
       "style": "IPY_MODEL_5a505a3ee60b4cec94a909ee77bc9e88",
       "value": "Loading graphs: 100%"
      }
     },
     "21287ad6d5e94484936bd93b6f85b49f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "24c3a3de365e4f25b0a1bea6f0fb668c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7418bd6443174ebf9271fa554d755cb6",
       "style": "IPY_MODEL_89249e08e1e3471682df33d354d7719a",
       "value": " 11534/11534 [02:08&lt;00:00, 135.57it/s]"
      }
     },
     "27d2c0b03e77463ca2d1ef57e2dbb80c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "40c664d572b84ef18b87ead26e1394fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "45147e50fc8f4baebe21cd0514d03651": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4df22612cbdf457690de3a21e160aa38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5a505a3ee60b4cec94a909ee77bc9e88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6e77e20f7c004d279691b884ca326aad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8b937b880a894a71a97b31715f2a1f4c",
        "IPY_MODEL_db06b803a3a24d01b9b1c2b1e05ae83a",
        "IPY_MODEL_1a6eaadc214a40b8a2fa048f934db6d0"
       ],
       "layout": "IPY_MODEL_4df22612cbdf457690de3a21e160aa38"
      }
     },
     "73376bdf366c44bfb463627255caa47e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_9e7c9d6193914fe0aaa1eebe6b6c059d",
       "max": 11534,
       "style": "IPY_MODEL_8b02a3651eb54471a990e3928f56d001",
       "value": 11534
      }
     },
     "7418bd6443174ebf9271fa554d755cb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "80769a69b258448ba022beb13ba6364a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "89249e08e1e3471682df33d354d7719a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8b02a3651eb54471a990e3928f56d001": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8b937b880a894a71a97b31715f2a1f4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_45147e50fc8f4baebe21cd0514d03651",
       "style": "IPY_MODEL_21287ad6d5e94484936bd93b6f85b49f",
       "value": "  3%"
      }
     },
     "93b07268006b4c8ea3508cc0a8708e7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9e7c9d6193914fe0aaa1eebe6b6c059d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "db06b803a3a24d01b9b1c2b1e05ae83a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_f4c410d18e994023b2ba1fc6ed46b5d1",
       "max": 79,
       "style": "IPY_MODEL_e659a35bdcf6428abeb1b6f9c003c325",
       "value": 2
      }
     },
     "dcc6a4b6eeac482ab4b1935722126823": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1d73892e8c254708ad3918446d1b971d",
        "IPY_MODEL_73376bdf366c44bfb463627255caa47e",
        "IPY_MODEL_24c3a3de365e4f25b0a1bea6f0fb668c"
       ],
       "layout": "IPY_MODEL_93b07268006b4c8ea3508cc0a8708e7a"
      }
     },
     "e659a35bdcf6428abeb1b6f9c003c325": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f4c410d18e994023b2ba1fc6ed46b5d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
